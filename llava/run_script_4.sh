    --lora_enable True 
    --model_name_or_path liuhaotian/llava-v1.5-13b
    --data_path /mnt/bulentsiyah/multimodal-fine-tuning/data/jsons/synthetic/df_clock.json
    --eval_data_path /mnt/bulentsiyah/multimodal-fine-tuning/data/jsons/synthetic/df_clock_test.json
    --train_image_folder /mnt/bulentsiyah/multimodal-fine-tuning/data/datasets/syn_dataset/train_data
    --eval_image_folder /mnt/bulentsiyah/multimodal-fine-tuning/data/datasets/syn_dataset/val_data
    --pretrain_mm_mlp_adapter /mnt/bulentsiyah/multimodal-fine-tuning/llava/mm_projector.bin
    --vision_tower openai/clip-vit-large-patch14 
    --mm_vision_select_layer -2 
    --mm_use_im_start_end False 
    --mm_use_im_patch_token False 
    --load_best_model_at_end True
    --bf16 True 
    --output_dir /mnt/bulentsiyah/multimodal-fine-tuning/llava/results/parameter_optimization/8_2e-6_003
    --cache_dir /mnt/bulentsiyah/multimodal-fine-tuning/llava/fine_tuning_llava_beta_clock
    --num_train_epochs 3
    --per_device_train_batch_size 8
    --per_device_eval_batch_size 4 
    --gradient_accumulation_steps 1 
    --evaluation_strategy steps
    --eval_steps 50
    --save_strategy steps 
    --save_steps 50 
    --save_total_limit 1 
    --learning_rate 2e-6
    --weight_decay 0. 
    --warmup_ratio 0.03 
    --lr_scheduler_type cosine 
    --logging_steps 1 
    --model_max_length 2048
    --tf32 True 
    --gradient_checkpointing True 
    --lazy_preprocess True 
    --dataloader_num_workers 4 
    --report_to wandb